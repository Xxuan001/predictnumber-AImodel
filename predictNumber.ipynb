{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this a ai modle traning for recogineztingh the numbers from handwritings. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(gamma=0.001):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.97      0.99        34\n",
      "           4       1.00      1.00      1.00        46\n",
      "           5       0.98      0.98      0.98        47\n",
      "           6       0.97      1.00      0.99        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       0.97      0.97      0.97        40\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Flatten the images into a 1D array\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create a Support Vector Classifier (SVC) model\n",
    "clf = svm.SVC(gamma=0.001)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\n",
    "    f\"Classification report for classifier {clf}:\\n\"\n",
    "    f\"{metrics.classification_report(y_test, predicted)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8685 - loss: 0.4474 - val_accuracy: 0.9776 - val_loss: 0.0744\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0563 - val_accuracy: 0.9827 - val_loss: 0.0599\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9880 - loss: 0.0371 - val_accuracy: 0.9846 - val_loss: 0.0499\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9908 - loss: 0.0278 - val_accuracy: 0.9859 - val_loss: 0.0464\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9924 - loss: 0.0247 - val_accuracy: 0.9883 - val_loss: 0.0405\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0391\n",
      "Test accuracy: 0.99\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "x_train = x_train / 255.0  # Normalize pixel values\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Reshape data to add channel dimension (for CNNs)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Step 3: Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Step 7: Make predictions\n",
    "def predict_number(image):\n",
    "    image = image.reshape(1, 28, 28, 1)  # Reshape to match model input\n",
    "    prediction = np.argmax(model.predict(image))\n",
    "    return prediction\n",
    "\n",
    "# Visualize and predict a sample image\n",
    "sample_image = x_test[0]\n",
    "plt.imshow(sample_image.squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted: {predict_number(sample_image)}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notice the input need to be a image and I want a easiler way to input throught the prediction model,\n",
    "# so import a drawing interface is the first idea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8734 - loss: 0.4298 - val_accuracy: 0.9795 - val_loss: 0.0661\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9806 - loss: 0.0616 - val_accuracy: 0.9828 - val_loss: 0.0559\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9876 - loss: 0.0417 - val_accuracy: 0.9883 - val_loss: 0.0421\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9907 - loss: 0.0296 - val_accuracy: 0.9876 - val_loss: 0.0439\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9936 - loss: 0.0216 - val_accuracy: 0.9873 - val_loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-29 18:13:07.957 Python[7585:6646892] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-12-29 18:13:07.957 Python[7585:6646892] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Predicted Digit: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted Digit: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted Digit: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted Digit: 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Predicted Digit: 3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Predicted Digit: 4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Predicted Digit: 9\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Predicted Digit: 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDraw a Digit\u001b[39m\u001b[38;5;124m\"\u001b[39m, draw)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDraw a Digit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# Clear the canvas\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import normalize\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "x_train = x_train / 255.0  # Normalize pixel values\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Reshape data to add channel dimension (for CNNs)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Step 3: Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])\n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 5: Train the model (uncomment to train the model)\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the trained model to a file\n",
    "model.save('my_model.h5')  # Save the model after training\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n",
    "\n",
    "####################################\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('my_model.h5')  # Replace with your saved model's path\n",
    "\n",
    "# Create a blank canvas and callback function for drawing\n",
    "canvas = np.zeros((400, 400), dtype=\"uint8\")  # Black canvas\n",
    "drawing = False  # Flag to indicate drawing state\n",
    "\n",
    "def draw(event, x, y, flags, param):\n",
    "    global drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Start drawing\n",
    "        drawing = True\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and drawing:  # Draw\n",
    "        cv2.circle(canvas, (x, y), 8, (255, 255, 255), -1)  # Draw white circles\n",
    "    elif event == cv2.EVENT_LBUTTONUP:  # Stop drawing\n",
    "        drawing = False\n",
    "\n",
    "# Set up OpenCV window and callback\n",
    "cv2.namedWindow(\"Draw a Digit\")\n",
    "cv2.setMouseCallback(\"Draw a Digit\", draw)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Draw a Digit\", canvas)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"c\"):  # Clear the canvas\n",
    "        canvas = np.zeros((400, 400), dtype=\"uint8\")\n",
    "    elif key == ord(\"q\"):  # Quit the application\n",
    "        break\n",
    "    elif key == ord(\"p\"):  # Predict the digit\n",
    "        # Preprocess the canvas for prediction\n",
    "        resized = cv2.resize(canvas, (28, 28))  # Resize to 28x28\n",
    "        normalized = normalize(resized, axis=-1)  # Normalize pixel values\n",
    "        reshaped = normalized.reshape(1, 28, 28, 1)  # Add batch and channel dimensions\n",
    "\n",
    "        # Predict the digit\n",
    "        prediction = np.argmax(model.predict(reshaped))\n",
    "        print(f\"Predicted Digit: {prediction}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
